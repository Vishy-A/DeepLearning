{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOnQtGl3zYCj8mbsYwEycuG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vishy-A/DeepLearning/blob/main/4106HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "ZMLVOVR0NmGA"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from google.colab import drive\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch.nn as nn\n",
        "from collections import OrderedDict\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "from torch.utils.data import DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "data_path = '../data-unversioned/p1ch6/'\n",
        "cifar10 = datasets.CIFAR10(\n",
        "    data_path, train=True, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))\n",
        "\n",
        "cifar10_val = datasets.CIFAR10(\n",
        "    data_path, train=False, download=True,\n",
        "    transform=transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                           (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_fhskp0NwS7",
        "outputId": "2ecf3c19-df64-431c-a3c6-9ea7ee7da0b5"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "9Rfm5OSkN7ex"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"CUDA (GPU) is available.\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"CUDA (GPU) is not available. Using CPU.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXIKP8SKQfDQ",
        "outputId": "8db8d76f-68e5-4515-b04b-a8394be18504"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA (GPU) is available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def trainingloop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss_train = 0.0\n",
        "        for imgs, labels in train_loader:\n",
        "            outputs = model(imgs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_train += loss.item()\n",
        "\n",
        "        if epoch == 1 or epoch % 10 == 0:\n",
        "            print('Epoch {}, Training loss {}'.format(epoch, loss_train / len(train_loader)))"
      ],
      "metadata": {
        "id": "cOAFIvcTRQqG"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validateloop(model, train_loader, val_loader):\n",
        "      for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "          correct = 0\n",
        "          total = 0\n",
        "\n",
        "\n",
        "\n",
        "          alllabels = []\n",
        "          allpreds = []\n",
        "\n",
        "          with torch.no_grad():\n",
        "              for imgs, labels in loader:\n",
        "                  outputs = model(imgs)\n",
        "                  _, predicted = torch.max(outputs, dim=1)\n",
        "                  total += labels.shape[0]\n",
        "                  correct += int((predicted == labels).sum())\n",
        "\n",
        "                  alllabels.extend(labels.cpu().numpy())\n",
        "                  allpreds.extend(predicted.cpu().numpy())\n",
        "\n",
        "          print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
        "\n",
        "          alllabels = np.array(alllabels)\n",
        "          allpreds = np.array(allpreds)\n",
        "\n",
        "          report = classification_report(alllabels, allpreds)\n",
        "          print(f\"Classification Report {name}:\\n{report}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "_fqhRxY4UgGY"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(32 * 32 * 3, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return torch.softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "0pIEPpEwVMWx"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = DataLoader(cifar10, batch_size=64, shuffle=True)\n",
        "valloader = DataLoader(cifar10_val, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "vcWjMZ9rVcCb"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Network()\n",
        "lossfunc = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
        "epochsReported = [1, 10, 20]"
      ],
      "metadata": {
        "id": "2po4ed1kYbiy"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainingloop(\n",
        "    n_epochs = 20,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = lossfunc,\n",
        "    train_loader = valloader,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNCUxwHZAGf9",
        "outputId": "1097b732-86cf-4d8d-8830-b4f24b3816bb"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training loss 2.3022934813408336\n",
            "Epoch 10, Training loss 2.2760231434159977\n",
            "Epoch 20, Training loss 2.2084268415050143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validateloop(model, trainloader, valloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKrPEVmdAQ_e",
        "outputId": "4df332f4-cf36-42fa-be9a-05391ac43a9b"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy train: 0.25\n",
            "Classification Report train:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.29      0.47      0.36      5000\n",
            "           1       0.00      0.00      0.00      5000\n",
            "           2       0.00      0.00      0.00      5000\n",
            "           3       0.00      0.00      0.00      5000\n",
            "           4       0.00      0.00      0.00      5000\n",
            "           5       0.25      0.26      0.25      5000\n",
            "           6       0.20      0.59      0.30      5000\n",
            "           7       0.00      0.00      0.00      5000\n",
            "           8       0.34      0.58      0.43      5000\n",
            "           9       0.24      0.63      0.34      5000\n",
            "\n",
            "    accuracy                           0.25     50000\n",
            "   macro avg       0.13      0.25      0.17     50000\n",
            "weighted avg       0.13      0.25      0.17     50000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy val: 0.26\n",
            "Classification Report val:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.52      0.38      1000\n",
            "           1       0.00      0.00      0.00      1000\n",
            "           2       0.00      0.00      0.00      1000\n",
            "           3       0.00      0.00      0.00      1000\n",
            "           4       0.00      0.00      0.00      1000\n",
            "           5       0.26      0.26      0.26      1000\n",
            "           6       0.20      0.58      0.30      1000\n",
            "           7       0.00      0.00      0.00      1000\n",
            "           8       0.34      0.60      0.44      1000\n",
            "           9       0.23      0.62      0.34      1000\n",
            "\n",
            "    accuracy                           0.26     10000\n",
            "   macro avg       0.13      0.26      0.17     10000\n",
            "weighted avg       0.13      0.26      0.17     10000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x7Z2GMaYD2GD"
      },
      "execution_count": 110,
      "outputs": []
    }
  ]
}