{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN/30rHnSkYOuu9MgNoMaOE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vishy-A/DeepLearning/blob/main/HW2/4106HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "jXcwzAq9DNAQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"CUDA (GPU) is available.\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"CUDA (GPU) is not available. Using CPU.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0dOyfY9GbFj",
        "outputId": "3621e7e9-f9c5-4f2e-c323-e954d6237e24"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA (GPU) is available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '../data-unversioned/p1ch6/'\n",
        "cifar10 = datasets.CIFAR10(\n",
        "    data_path, train=True, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))\n",
        "\n",
        "cifar10_val = datasets.CIFAR10(\n",
        "    data_path, train=False, download=True,\n",
        "    transform=transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                           (0.2470, 0.2435, 0.2616))\n",
        "    ]))\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(cifar10, batch_size=32, shuffle=True)\n",
        "valloader = torch.utils.data.DataLoader(cifar10_val, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeubwrbCMBok",
        "outputId": "8f761186-d970-4cc8-e9c3-e6b9a8709e70"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes = 10):\n",
        "        super(AlexNet, self). __init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(128, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(512, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(2048, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "          x = self.layers(x)\n",
        "          x = torch.flatten(x, 1)\n",
        "          return x"
      ],
      "metadata": {
        "id": "ejmyva5BDQ5S"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = 10\n",
        "epochs = 20\n",
        "lr = .001\n",
        "\n",
        "steps = len(trainloader)\n",
        "trainingloss = []\n",
        "validationloss = []\n",
        "valacc = []\n",
        "\n",
        "model = AlexNet(classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n"
      ],
      "metadata": {
        "id": "29AT3NZ1HY3y"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    trainloss = 0;\n",
        "    valloss = 0;\n",
        "    correct = 0;\n",
        "    total = 0;\n",
        "\n",
        "    model.train()\n",
        "    for images, labels in trainloader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        trainloss = trainloss + loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for images, labels in valloader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            valloss = valloss + loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    valacc = (100 * correct / total)\n",
        "    valloss = valloss / len(valloader)\n",
        "    trainloss = trainloss / len(trainloader)\n",
        "\n",
        "    print('Epoch: {}/{}'.format(epoch+1, epochs))\n",
        "    print('Training Loss: {:.4f}'.format(trainloss))\n",
        "    print('Validation Loss: {:.4f}'.format(valloss))\n",
        "    print('Accuracy: {:.4f}'.format(valacc))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GW_7czWP7nB",
        "outputId": "0c5df41b-137d-4b1d-d83b-71fe76f405a8"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/20\n",
            "Training Loss: 2.2973\n",
            "Validation Loss: 2.2909\n",
            "Accuracy: 21.4900\n",
            "Epoch: 2/20\n",
            "Training Loss: 2.2759\n",
            "Validation Loss: 2.2458\n",
            "Accuracy: 18.3300\n",
            "Epoch: 3/20\n",
            "Training Loss: 2.1546\n",
            "Validation Loss: 2.0384\n",
            "Accuracy: 27.5000\n",
            "Epoch: 4/20\n",
            "Training Loss: 1.9574\n",
            "Validation Loss: 1.8791\n",
            "Accuracy: 33.1300\n",
            "Epoch: 5/20\n",
            "Training Loss: 1.8288\n",
            "Validation Loss: 1.7604\n",
            "Accuracy: 36.6400\n",
            "Epoch: 6/20\n",
            "Training Loss: 1.7220\n",
            "Validation Loss: 1.6655\n",
            "Accuracy: 39.3700\n",
            "Epoch: 7/20\n",
            "Training Loss: 1.6331\n",
            "Validation Loss: 1.5808\n",
            "Accuracy: 42.5700\n",
            "Epoch: 8/20\n",
            "Training Loss: 1.5725\n",
            "Validation Loss: 1.5452\n",
            "Accuracy: 43.4300\n",
            "Epoch: 9/20\n",
            "Training Loss: 1.5276\n",
            "Validation Loss: 1.5207\n",
            "Accuracy: 44.4600\n",
            "Epoch: 10/20\n",
            "Training Loss: 1.4914\n",
            "Validation Loss: 1.4850\n",
            "Accuracy: 46.3300\n",
            "Epoch: 11/20\n",
            "Training Loss: 1.4613\n",
            "Validation Loss: 1.4349\n",
            "Accuracy: 47.6900\n",
            "Epoch: 12/20\n",
            "Training Loss: 1.4309\n",
            "Validation Loss: 1.4218\n",
            "Accuracy: 47.4800\n",
            "Epoch: 13/20\n",
            "Training Loss: 1.3998\n",
            "Validation Loss: 1.3793\n",
            "Accuracy: 49.8100\n",
            "Epoch: 14/20\n",
            "Training Loss: 1.3696\n",
            "Validation Loss: 1.3542\n",
            "Accuracy: 51.0600\n",
            "Epoch: 15/20\n",
            "Training Loss: 1.3429\n",
            "Validation Loss: 1.3287\n",
            "Accuracy: 51.6700\n",
            "Epoch: 16/20\n",
            "Training Loss: 1.3178\n",
            "Validation Loss: 1.3056\n",
            "Accuracy: 53.0600\n",
            "Epoch: 17/20\n",
            "Training Loss: 1.2920\n",
            "Validation Loss: 1.2718\n",
            "Accuracy: 54.3100\n",
            "Epoch: 18/20\n",
            "Training Loss: 1.2671\n",
            "Validation Loss: 1.3007\n",
            "Accuracy: 53.3000\n",
            "Epoch: 19/20\n",
            "Training Loss: 1.2456\n",
            "Validation Loss: 1.2882\n",
            "Accuracy: 53.8300\n",
            "Epoch: 20/20\n",
            "Training Loss: 1.2211\n",
            "Validation Loss: 1.3386\n",
            "Accuracy: 52.5400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "evU0bn7bQ7Aq"
      },
      "execution_count": 59,
      "outputs": []
    }
  ]
}