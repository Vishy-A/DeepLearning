{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "authorship_tag": "ABX9TyOygqytkjwyGn21h3HrBbih",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vishy-A/DeepLearning/blob/main/HW3/4106HW3P2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "amsdX0H4X8jP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import requests\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "response = requests.get(url)\n",
        "seq = response.text"
      ],
      "metadata": {
        "id": "vdgogVhkYCRR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tAigEwJgmGo",
        "outputId": "48c2a58a-107a-4cec-dd8f-9f66d61ff8a1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(seq)))\n",
        "char_to_int = {ch: i for i, ch in enumerate(chars)}\n",
        "int_to_char = {i: ch for i, ch in enumerate(chars)}\n",
        "encoded_text = [char_to_int[ch] for ch in seq]"
      ],
      "metadata": {
        "id": "rgtIdD4cYZXr"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def definition(maxlen):\n",
        "  x = []\n",
        "  y = []\n",
        "  for i in range(len(seq) - maxlen):\n",
        "      sequence = seq[i:i + maxlen]\n",
        "      label = seq[i + maxlen]\n",
        "      x.append([char_to_int[char] for char in sequence])\n",
        "      y.append(char_to_int[label])\n",
        "\n",
        "  x = np.array(x)\n",
        "  y = np.array(y)\n",
        "\n",
        "  return x, y"
      ],
      "metadata": {
        "id": "ABnYEXn_YExY"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x20, y20 = definition(20)\n",
        "x30, y30 = definition(30)\n",
        "x50, y50 = definition(50)"
      ],
      "metadata": {
        "id": "P0b5h0LlYT2b"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x20 = torch.tensor(x20, dtype=torch.long)\n",
        "y20 = torch.tensor(y20, dtype=torch.long)\n",
        "\n",
        "x30 = torch.tensor(x30, dtype=torch.long)\n",
        "y30 = torch.tensor(y30, dtype=torch.long)\n",
        "\n",
        "x50 = torch.tensor(x50, dtype=torch.long)\n",
        "y50 = torch.tensor(y50, dtype=torch.long)\n"
      ],
      "metadata": {
        "id": "cjA-L96xZ7Zr"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CharDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]\n"
      ],
      "metadata": {
        "id": "1myKPXLEaTqf"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset20 = CharDataset(x20, y20)\n",
        "dataset30 = CharDataset(x30, y30)\n",
        "dataset50 = CharDataset(x50, y50)"
      ],
      "metadata": {
        "id": "XAW2DKR6aZG7"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "\n",
        "trainsize20 = int(len(dataset20) * .8)\n",
        "valsize20 = len(dataset20) - trainsize20\n",
        "traindataset20, valdataset20 = torch.utils.data.random_split(dataset20, [trainsize20, valsize20])\n",
        "\n",
        "trainsize30 = int(len(dataset30) * .8)\n",
        "valsize30 = len(dataset30) - trainsize30\n",
        "traindataset30, valdataset30 = torch.utils.data.random_split(dataset30, [trainsize30, valsize30])\n",
        "\n",
        "trainsize50 = int(len(dataset50) * .8)\n",
        "valsize50 = len(dataset50) - trainsize50\n",
        "traindataset50, valdataset50 = torch.utils.data.random_split(dataset50, [trainsize50, valsize50])\n"
      ],
      "metadata": {
        "id": "4FiD0DNjalwI"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader20 = DataLoader(traindataset20, batch_size=batch_size, shuffle=True)\n",
        "testloader20 = DataLoader(valdataset20, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "trainloader30 = DataLoader(traindataset30, batch_size=batch_size, shuffle=True)\n",
        "testloader30 = DataLoader(valdataset30, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "trainloader50 = DataLoader(traindataset50, batch_size=batch_size, shuffle=True)\n",
        "testloader50 = DataLoader(valdataset50, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "CIziSWvPa80W"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(LSTM, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "    self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
        "    self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, input):\n",
        "    embedded = self.embedding(input)\n",
        "    output, _ = self.lstm(embedded)\n",
        "    output = self.fc(output[:, -1, :])\n",
        "    return output"
      ],
      "metadata": {
        "id": "rKYEKyJYbESf"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GRU(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(GRU, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "    self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "    self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, input):\n",
        "    embedded = self.embedding(input)\n",
        "    output, _ = self.gru(embedded)\n",
        "    output = self.fc(output[:, -1, :])\n",
        "    return output"
      ],
      "metadata": {
        "id": "30EVQ_1zbI7A"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 128\n",
        "lr = .001\n",
        "epochs = 10\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "4gm3UyxFbjEP"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelLSTM = LSTM(len(chars), hidden_size, len(chars))\n",
        "modelGRU = GRU(len(chars), hidden_size, len(chars))\n",
        "\n",
        "optimizerLSTM = torch.optim.Adam(modelLSTM.parameters(), lr=lr)\n",
        "optimizerGRU = torch.optim.Adam(modelGRU.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "Qm9YpeNIboXm"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trainloop(train, test, model, lossfunc, optimizer, epochs):\n",
        "  model.to(device)\n",
        "\n",
        "  train_losses = []\n",
        "  test_losses = []\n",
        "  test_accs = []\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    train_loss = 0\n",
        "    test_loss = 0\n",
        "    test_acc = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.train()\n",
        "\n",
        "    for x, y in train:\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      output = model(x)\n",
        "      loss = lossfunc(output, y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      train_loss += loss.item()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for x, y in test:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        output = model(x)\n",
        "        test_loss += lossfunc(output, y).item()\n",
        "        pred = torch.argmax(output, dim=1)\n",
        "        correct += torch.sum(pred == y).item()\n",
        "        total += len(y)\n",
        "\n",
        "    train_loss /= len(train)\n",
        "    test_loss /= len(test)\n",
        "\n",
        "    train_losses.append(train_loss / len(train))\n",
        "    test_losses.append(test_loss / len(test))\n",
        "    test_accs.append(correct / total)\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {correct / total:.4f}')\n",
        "\n",
        "  return train_losses, test_losses, test_accs\n",
        ""
      ],
      "metadata": {
        "id": "jMwVU3zwgd2Q"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_char(model, char_to_int, int_to_char, initialstr):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    initial_input = torch.tensor([char_to_int[char] for char in initialstr], dtype=torch.long).unsqueeze(0)\n",
        "    output = model(initial_input)\n",
        "    predicted = torch.argmax(output, dim=1).item()\n",
        "    return int_to_char[predicted]"
      ],
      "metadata": {
        "id": "bIKjjeDJb6Gm"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloop(trainloader20, testloader20, modelLSTM, criterion, optimizerLSTM, epochs)\n",
        "trainloop(trainloader20, testloader20, modelGRU, criterion, optimizerGRU, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laN9jn2khtui",
        "outputId": "7258afbb-25c5-4853-e0d6-071175e09cee"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Loss: 2.5015, Test Loss: 2.4715, Test Accuracy: 0.2696\n",
            "Epoch 2/10, Train Loss: 2.4696, Test Loss: 2.4695, Test Accuracy: 0.2672\n",
            "Epoch 3/10, Train Loss: 2.4665, Test Loss: 2.4676, Test Accuracy: 0.2686\n",
            "Epoch 4/10, Train Loss: 2.4653, Test Loss: 2.4664, Test Accuracy: 0.2692\n",
            "Epoch 5/10, Train Loss: 2.4647, Test Loss: 2.4665, Test Accuracy: 0.2680\n",
            "Epoch 6/10, Train Loss: 2.4640, Test Loss: 2.4642, Test Accuracy: 0.2685\n",
            "Epoch 7/10, Train Loss: 2.4640, Test Loss: 2.4650, Test Accuracy: 0.2689\n",
            "Epoch 8/10, Train Loss: 2.4638, Test Loss: 2.4649, Test Accuracy: 0.2697\n",
            "Epoch 9/10, Train Loss: 2.4635, Test Loss: 2.4642, Test Accuracy: 0.2694\n",
            "Epoch 10/10, Train Loss: 2.4633, Test Loss: 2.4643, Test Accuracy: 0.2690\n",
            "Epoch 1/10, Train Loss: 2.4998, Test Loss: 2.4769, Test Accuracy: 0.2540\n",
            "Epoch 2/10, Train Loss: 2.4743, Test Loss: 2.4748, Test Accuracy: 0.2652\n",
            "Epoch 3/10, Train Loss: 2.4725, Test Loss: 2.4761, Test Accuracy: 0.2684\n",
            "Epoch 4/10, Train Loss: 2.4722, Test Loss: 2.4752, Test Accuracy: 0.2637\n",
            "Epoch 5/10, Train Loss: 2.4714, Test Loss: 2.4705, Test Accuracy: 0.2640\n",
            "Epoch 6/10, Train Loss: 2.4716, Test Loss: 2.4746, Test Accuracy: 0.2695\n",
            "Epoch 7/10, Train Loss: 2.4715, Test Loss: 2.4709, Test Accuracy: 0.2687\n",
            "Epoch 8/10, Train Loss: 2.4713, Test Loss: 2.4727, Test Accuracy: 0.2682\n",
            "Epoch 9/10, Train Loss: 2.4710, Test Loss: 2.4719, Test Accuracy: 0.2675\n",
            "Epoch 10/10, Train Loss: 2.4706, Test Loss: 2.4717, Test Accuracy: 0.2621\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.00035854778919976546,\n",
              "  0.00035488602484259007,\n",
              "  0.0003546340210085993,\n",
              "  0.00035458736716712826,\n",
              "  0.00035447344318711874,\n",
              "  0.0003545027648003062,\n",
              "  0.0003544936577920481,\n",
              "  0.0003544600422219924,\n",
              "  0.00035441741481239737,\n",
              "  0.0003543659593821605],\n",
              " [0.001421083714602705,\n",
              "  0.0014198722744064914,\n",
              "  0.0014205921166060348,\n",
              "  0.0014200964733281675,\n",
              "  0.0014174061331191392,\n",
              "  0.0014197532884247497,\n",
              "  0.0014175956153868812,\n",
              "  0.0014186199198719532,\n",
              "  0.001418190603761348,\n",
              "  0.0014180980931158115],\n",
              " [0.2540177070491987,\n",
              "  0.26517538944301244,\n",
              "  0.26837162389330943,\n",
              "  0.2637229631289925,\n",
              "  0.2639784825731256,\n",
              "  0.2695416339796033,\n",
              "  0.2686988680936905,\n",
              "  0.26821472598901713,\n",
              "  0.26749299562927265,\n",
              "  0.26205536254622885])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelLSTM = LSTM(len(chars), hidden_size, len(chars))\n",
        "modelGRU = GRU(len(chars), hidden_size, len(chars))\n",
        "\n",
        "optimizerLSTM = torch.optim.Adam(modelLSTM.parameters(), lr=lr)\n",
        "optimizerGRU = torch.optim.Adam(modelGRU.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "gHUxckx5keCH"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloop(trainloader30, testloader30, modelLSTM, criterion, optimizerLSTM, epochs)\n",
        "trainloop(trainloader30, testloader30, modelGRU, criterion, optimizerGRU, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Scvfxi8Rh7T9",
        "outputId": "4c5a4a65-66aa-4568-f9c2-f5a3ebbc6aee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Loss: 2.5022, Test Loss: 2.4764, Test Accuracy: 0.2612\n",
            "Epoch 2/10, Train Loss: 2.4691, Test Loss: 2.4689, Test Accuracy: 0.2678\n",
            "Epoch 3/10, Train Loss: 2.4662, Test Loss: 2.4686, Test Accuracy: 0.2679\n",
            "Epoch 4/10, Train Loss: 2.4653, Test Loss: 2.4667, Test Accuracy: 0.2676\n",
            "Epoch 5/10, Train Loss: 2.4645, Test Loss: 2.4671, Test Accuracy: 0.2628\n",
            "Epoch 6/10, Train Loss: 2.4640, Test Loss: 2.4692, Test Accuracy: 0.2696\n",
            "Epoch 7/10, Train Loss: 2.4636, Test Loss: 2.4665, Test Accuracy: 0.2682\n",
            "Epoch 8/10, Train Loss: 2.4635, Test Loss: 2.4648, Test Accuracy: 0.2675\n",
            "Epoch 9/10, Train Loss: 2.4633, Test Loss: 2.4651, Test Accuracy: 0.2702\n",
            "Epoch 10/10, Train Loss: 2.4631, Test Loss: 2.4659, Test Accuracy: 0.2690\n",
            "Epoch 1/10, Train Loss: 2.4991, Test Loss: 2.4795, Test Accuracy: 0.2675\n",
            "Epoch 2/10, Train Loss: 2.4745, Test Loss: 2.4743, Test Accuracy: 0.2693\n",
            "Epoch 3/10, Train Loss: 2.4726, Test Loss: 2.4740, Test Accuracy: 0.2695\n",
            "Epoch 4/10, Train Loss: 2.4718, Test Loss: 2.4776, Test Accuracy: 0.2673\n",
            "Epoch 5/10, Train Loss: 2.4715, Test Loss: 2.4758, Test Accuracy: 0.2635\n",
            "Epoch 6/10, Train Loss: 2.4713, Test Loss: 2.4773, Test Accuracy: 0.2686\n",
            "Epoch 7/10, Train Loss: 2.4716, Test Loss: 2.4722, Test Accuracy: 0.2657\n",
            "Epoch 8/10, Train Loss: 2.4707, Test Loss: 2.4734, Test Accuracy: 0.2679\n",
            "Epoch 9/10, Train Loss: 2.4705, Test Loss: 2.4742, Test Accuracy: 0.2658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelLSTM = LSTM(len(chars), hidden_size, len(chars))\n",
        "modelGRU = GRU(len(chars), hidden_size, len(chars))\n",
        "\n",
        "optimizerLSTM = torch.optim.Adam(modelLSTM.parameters(), lr=lr)\n",
        "optimizerGRU = torch.optim.Adam(modelGRU.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "GkX6nD0_kdEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloop(trainloader50, testloader50, modelLSTM, criterion, optimizerLSTM, epochs)\n",
        "trainloop(trainloader50, testloader50, modelGRU, criterion, optimizerGRU, epochs)"
      ],
      "metadata": {
        "id": "c3f1vGWpkVjx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}